---
title: "HW 3"
author: "CC"
date: "10/14/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

## Problem 1

Load libraries
```{r}
library(tidyverse)
library(p8105.datasets)
library(knitr)
data(instacart)
```

# Describing the dataset

```{r}
instacart %>%
  group_by(aisle) %>%
  summarize(n = n()) %>%
  view()
```

This dataset is quite large, with `r nrow(instacart)` observations from 131,209 unique users. There is a single order per user, and each row represents a product from an order. For example, user 1 has an order id of 2539329, which functions as their unique identifier, and they ordered from instacart on Monday, the second day of the week at 8AM. The 1st item they added to their cart was Soda, listed in the product name column. There are a few other variables of interest, including whether or not the user has ordered an item in the past (reordered) and days since the user last ordered from instacart (days_since_prior_order). In total there are `r ncol(instacart)` variables.

There are 134 aisles, and by far the aisles with the most orders are fresh veggies and fresh fruits, with over 150,000 items ordered in each. This is followed by the packaged veggies/fruits aisle, from which about 78,000 items have been ordered. The next most popular aisles include dairy products like yogurt, packaged cheese, and milk.

# Making a plot

```{r}
count(instacart, aisle, name = "aisle_count") %>%
  arrange(desc(aisle_count))
  
plot = 
  instacart %>%
  count(aisle, name = "aisle_count") %>%
  filter(aisle_count > 10000) %>%
  ggplot(aes(x = reorder(aisle, -aisle_count), y = aisle_count)) + geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(
    title = "Number of Items From Popular Aisles",
    x = "Aisle",
    y = "Number of Items"
  )
  plot
```

# Making a table: most popular items in aisles

```{r}
instacart %>%
  group_by(product_name, aisle) %>%
  summarize(
    n_ordered = n()) %>%
  group_by(aisle) %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits"),
         min_rank(desc(n_ordered)) < 4 ) %>%
  arrange(n_ordered, aisle)
```

# Making a table: mean hour of the day items are ordered during the week

```{r}
fun_food = 
  instacart %>%
  rename(order_hour = order_hour_of_day) %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour_of_day = mean(order_hour)) %>%
  mutate(
    day_of_week = recode(order_dow,
                         '0' = "Sunday",
                         '1' = "Monday",
                         '2' = "Tuesday",
                         '3' = "Wednesday",
                         '4' = "Thursday",
                         '5' = "Friday",
                         '6' = "Saturday")) %>%
  separate(mean_hour_of_day, into = c("hour", "minutes"), sep = 2) %>%
  mutate(minutes = as.numeric(minutes),
         minutes = round(minutes*60, digits = 0),
         mean_hour_of_day = paste(hour, minutes, sep = ":")) %>%
  select(product_name, day_of_week, mean_hour_of_day) %>%
  pivot_wider(
    names_from = "product_name",
    values_from = "mean_hour_of_day") %>%
  kable(format = "pandoc", caption = "Mean Hour of Day Items Are Ordered")
fun_food
```

## Problem 2

```{r}
data(brfss_smart2010)

brfss = 
brfss_smart2010 %>%
  janitor::clean_names() %>%
  rename(
    state = locationabbr,
    county = locationdesc,
    cll = confidence_limit_low,
    clh = confidence_limit_high) %>%
  select(-data_value_footnote, -data_value_footnote_symbol, -location_id) %>%
  filter(topic == "Overall Health") %>%
  mutate(response = factor(response, c("Poor", "Fair", "Good", "Very good", "Excellent")))
```

# In 2002, which states were observed at 7 or more locations. What about in 2010?

```{r}
brfss_1 = 
  brfss %>%
  filter(year == "2010") %>%
  distinct(state, county) %>%
  count(state) %>%
  filter(n >= 7) %>%
  rename(number_sites = n)
brfss_1


brfss_2 =
  brfss %>%
  filter(year == "2002") %>%
  distinct(state, county) %>%
  count(state) %>%
  filter(n >= 7) %>%
  rename(number_sites = n)
brfss_2
  
```

There were 14 states observed in 2010 at 7 or more locations and 6 states observed in 2002 at 7 or more locations.

# Construct a dataset

```{r}
brfss_excellent =  
brfss %>%
  janitor::clean_names() %>%
  filter(response == "Excellent") %>%
  group_by(year, state) %>%
  summarize(data_value_ave = mean(data_value)) %>%
  ggplot(aes(x = year, y = data_value_ave, group = state, color = state)) + geom_line()
brfss_excellent
```

# Make a two-panel plot

```{r}
data_value_2010 = 
  brfss %>%
  group_by(response) %>% #how to order poor to excellent?
  filter(locationabbr == "NY", year == "2010") %>%
  ggplot(aes(x = , y = , color = )) + geom_point()

data_value_2006 =
  brfss %>%
  group_by(response) %>% #how to order poor to excellent?
  filter(locationabbr == "NY", year == "2006") %>%
  ggplot(aes(x = , y = , color = )) + geom_point()

(data_value_2010 + data_value_2006)
```

## Problem 3

```{r}
accel = 
  read.csv("accel_data.csv") %>%
  janitor::clean_names() %>%
  separate(day, into = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"), convert = TRUE) %>%
  mutate(Weekday = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday"),
         Weekend = c("Sunday", "Saturday"))
#error: column `Weekday` must be length 35 (the number of rows) or one, not 5
```

Describe resulting dataset.


# Aggregating data across minutes

```{r}
accel = 
  
```

# Making a single panel plot: 24hr activity each day

```{r}
accel = 
  
   ggplot(aes(x = day, y = activity, color = day)) + geom_point()
```

